import os
import logging
from src.load_model import load_mistral_model
from src.parse_documents import parse_documents
from src.embed_documents import embed_and_store
from src.run_qa import run_qa
from src.load_model import load_mistral_model

# ë¡œê·¸ ì„¤ì •: INFO ë ˆë²¨ë¡œ ì¶œë ¥, ê°„ë‹¨í•œ ì‹œê°„, ë ˆë²¨, ë©”ì‹œì§€ í˜•ì‹ ì ìš©
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def main():
    logging.info("1) Mistral-7B ëª¨ë¸ ë¡œë“œ ì‹œì‘")
    llm = load_mistral_model()
    logging.info("Mistral-7B ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

    logging.info("2) ë¬¸ì„œ íŒŒì‹± ì‹œì‘")
    doc_paths = [
        "data/sample.pdf",
        #"data/sample.docx"
    ]
    docs = parse_documents(doc_paths)
    logging.info(f"ë¬¸ì„œ íŒŒì‹± ì™„ë£Œ - ì´ {len(docs)} ê°œì˜ ì²­í¬ ìƒì„±ë¨")

    logging.info("3) ë¬¸ì„œ ì„ë² ë”© ë° Qdrant ì €ì¥ ì‹œì‘")
    vector_db = embed_and_store(docs)
    logging.info("ë¬¸ì„œ ì„ë² ë”© ë° Qdrant ì €ì¥ ì™„ë£Œ")

    logging.info("4) QA ì§ˆì˜ ì‹¤í–‰ ì‹œì‘")
    query = "ì´ ë¬¸ì„œì—ì„œ ì¤‘ìš”í•œ ê°œë… 3ê°€ì§€ë¥¼ ì•Œë ¤ì¤˜."
    answer, sources = run_qa(llm, vector_db, query)
    logging.info("QA ì§ˆì˜ ì‹¤í–‰ ì™„ë£Œ")

    logging.info("5) ê²°ê³¼ ì¶œë ¥")
    print("ğŸ” ê²€ìƒ‰ëœ ë¬¸ì„œì—ì„œ ì¶”ì¶œí•œ ë‹µë³€:")
    print(answer)

    print("\nğŸ“„ ì‚¬ìš©ëœ ë¬¸ì„œ ì¶œì²˜:")
    for doc in sources:
        print(doc.metadata)

if __name__ == "__main__":
    main()

